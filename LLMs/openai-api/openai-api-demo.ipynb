{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e291b18d-a1f0-4068-9290-c9b937567e3e",
      "metadata": {
        "id": "e291b18d-a1f0-4068-9290-c9b937567e3e"
      },
      "source": [
        "# Cracking Open the OpenAI API\n",
        "\n",
        "Code authored by: Xiaotian Wang\n",
        "\n",
        "Date: 04/16/2025\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f25acaea-c334-4254-8635-64270dc6c397",
      "metadata": {
        "id": "f25acaea-c334-4254-8635-64270dc6c397"
      },
      "source": [
        "### set-up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1edd17a3-6cde-4cdf-8f29-c9e1e533d390",
      "metadata": {
        "id": "1edd17a3-6cde-4cdf-8f29-c9e1e533d390",
        "outputId": "bc6e6a05-f1b5-4d8b-d4d7-6b24ff781191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sk'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ed67af8bba3a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msk\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmy_sk\u001b[0m \u001b[0;31m#import secret key from sk.py file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sk'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import openai\n",
        "from sk import my_sk #import secret key from sk.py file\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b30b225-6b7c-48ca-8c13-05a75146d6ae",
      "metadata": {
        "id": "0b30b225-6b7c-48ca-8c13-05a75146d6ae"
      },
      "outputs": [],
      "source": [
        "openai.api_key = my_sk # use imported sk or just copy-paste it here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1c75b3c4-cce9-4d82-888c-078a4e9ae1fa",
      "metadata": {
        "id": "1c75b3c4-cce9-4d82-888c-078a4e9ae1fa"
      },
      "source": [
        "### code"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "100350ea-c690-49d3-84cc-84b192c18500",
      "metadata": {
        "id": "100350ea-c690-49d3-84cc-84b192c18500"
      },
      "source": [
        "##### First call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb7a1c4f-b4dc-453f-8e63-bc016f2de35e",
      "metadata": {
        "id": "eb7a1c4f-b4dc-453f-8e63-bc016f2de35e"
      },
      "outputs": [],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6288eb8-03d7-45f5-9e40-3912afe2a39c",
      "metadata": {
        "id": "f6288eb8-03d7-45f5-9e40-3912afe2a39c",
        "outputId": "235c8c03-67bc-4342-cf56-8f8b05c3f8dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'chatcmpl-7dk1Jkf5SDm2422nYRPL9x0QrlhI4',\n",
              " 'object': 'chat.completion',\n",
              " 'created': 1689706049,\n",
              " 'model': 'gpt-3.5-turbo-0613',\n",
              " 'choices': [<OpenAIObject at 0x7f9d1a862b80> JSON: {\n",
              "    \"index\": 0,\n",
              "    \"message\": {\n",
              "      \"role\": \"assistant\",\n",
              "      \"content\": \"heart.\"\n",
              "    },\n",
              "    \"finish_reason\": \"stop\"\n",
              "  }],\n",
              " 'usage': <OpenAIObject at 0x7f9d1a862c70> JSON: {\n",
              "   \"prompt_tokens\": 10,\n",
              "   \"completion_tokens\": 2,\n",
              "   \"total_tokens\": 12\n",
              " }}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_completion.to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "340f7ccf-c599-443c-89d8-e509039d673b",
      "metadata": {
        "id": "340f7ccf-c599-443c-89d8-e509039d673b",
        "outputId": "56756b85-5b59-4fc6-bf46-cb455fa24b7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "heart.\n"
          ]
        }
      ],
      "source": [
        "# print the chat completion\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b0e3b38-0bb2-48de-9d3f-ee5013f4a689",
      "metadata": {
        "tags": [],
        "id": "9b0e3b38-0bb2-48de-9d3f-ee5013f4a689"
      },
      "source": [
        "##### max tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf02f54e-004e-409b-942d-74a4d855c2d5",
      "metadata": {
        "id": "cf02f54e-004e-409b-942d-74a4d855c2d5",
        "outputId": "e008bb62-36a5-4b31-e537-f42c569d3cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "heart\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 1)\n",
        "\n",
        "# print the chat completion\n",
        "print(chat_completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "800f966f-7370-46d3-ae12-c955565b9617",
      "metadata": {
        "id": "800f966f-7370-46d3-ae12-c955565b9617"
      },
      "source": [
        "##### n = number of chat completions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad49735c-88c2-4563-a1c6-0020a8905e8e",
      "metadata": {
        "id": "ad49735c-88c2-4563-a1c6-0020a8905e8e",
        "outputId": "63283695-e6df-477c-fee6-50f00318425d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "heart.\n",
            "heart and\n",
            "heart.\n",
            "\n",
            "heart,\n",
            "\n",
            "heart,\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 2,\n",
        "                                n=5)\n",
        "\n",
        "# print the chat completion\n",
        "for i in range(len(chat_completion.choices)):\n",
        "    print(chat_completion.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "183ffa97-eb11-4ca9-a8d4-29502ee0cdc6",
      "metadata": {
        "id": "183ffa97-eb11-4ca9-a8d4-29502ee0cdc6"
      },
      "source": [
        "##### temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "638b828b-b323-4cd8-90ea-5106146635a0",
      "metadata": {
        "id": "638b828b-b323-4cd8-90ea-5106146635a0",
        "outputId": "8fed2dad-6301-4568-f7fc-a2a436c43cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "heart.\n",
            "heart.\n",
            "heart.\n",
            "heart.\n",
            "heart.\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 2,\n",
        "                                n=5,\n",
        "                                temperature=0)\n",
        "\n",
        "# print the chat completion\n",
        "for i in range(len(chat_completion.choices)):\n",
        "    print(chat_completion.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b78dd7ad-5790-441f-981d-60de6c61104d",
      "metadata": {
        "id": "b78dd7ad-5790-441f-981d-60de6c61104d",
        "outputId": "6a0c01ea-a232-4c87-a78a-58cf09fc1450"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "judgment\n",
            "Advice\n",
            ".inner awareness\n",
            "heart.\n",
            "\n",
            "ging ist\n"
          ]
        }
      ],
      "source": [
        "# create a chat completion\n",
        "chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                messages=[{\"role\": \"user\", \"content\": \"Listen to your\"}],\n",
        "                                max_tokens = 2,\n",
        "                                n=5,\n",
        "                                temperature=2)\n",
        "\n",
        "# print the chat completion\n",
        "for i in range(len(chat_completion.choices)):\n",
        "    print(chat_completion.choices[i].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc228536-a0b6-4a7f-81f7-382c3205ee8a",
      "metadata": {
        "tags": [],
        "id": "cc228536-a0b6-4a7f-81f7-382c3205ee8a"
      },
      "source": [
        "### Demo: Lyric Completion Assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ece8e6a6-ebe0-4ff1-b132-e8bc8759e1e6",
      "metadata": {
        "id": "ece8e6a6-ebe0-4ff1-b132-e8bc8759e1e6"
      },
      "outputs": [],
      "source": [
        "# initial prompt with system message and 2 task examples\n",
        "messages_list = [{\"role\":\"system\", \"content\": \"I am Roxette lyric completion assistant. When given a line from a song, I will provide the next line in the song.\"},\n",
        "                 {\"role\":\"user\", \"content\": \"I know there's something in the wake of your smile\"},\n",
        "                 {\"role\":\"assistant\", \"content\": \"I get a notion from the look in your eyes, yeah\"},\n",
        "                 {\"role\":\"user\", \"content\": \"You've built a love but that love falls apart\"},\n",
        "                 {\"role\":\"assistant\", \"content\": \"Your little piece of Heaven turns too dark\"},\n",
        "                 {\"role\":\"user\", \"content\": \"Listen to your\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b51fdc0-7f91-4524-a27e-739a9fb3f795",
      "metadata": {
        "id": "3b51fdc0-7f91-4524-a27e-739a9fb3f795",
        "outputId": "96eee6d9-89d4-4210-8bf9-1ebf6cf84e2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Heart when he's calling for you\n",
            "Listen to your heart, there's nothing else you can do\n",
            "I don't know where you're going and I don't know why\n",
            "But listen to your heart before you tell him goodbye\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "    # create a chat completion\n",
        "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                    messages=messages_list,\n",
        "                                    max_tokens = 15,\n",
        "                                    n=1,\n",
        "                                    temperature=0)\n",
        "\n",
        "    # print the chat completion\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "\n",
        "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content} # append new message to message list\n",
        "    messages_list.append(new_message)\n",
        "    time.sleep(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2168d7-8842-47d0-a7cc-02c5ea505a41",
      "metadata": {
        "id": "4c2168d7-8842-47d0-a7cc-02c5ea505a41"
      },
      "outputs": [],
      "source": [
        "# Actual lyrics:\n",
        "\n",
        "# Listen to your heart when he's calling for you\n",
        "# Listen to your heart, there's nothing else you can do\n",
        "# I don't know where you're going and I don't know why\n",
        "# But listen to your heart before you tell him goodbye"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b588989b-dc89-4c3b-898e-05aec70a8426",
      "metadata": {
        "id": "b588989b-dc89-4c3b-898e-05aec70a8426"
      },
      "source": [
        "##### Crank the temp! (warning: it gets weird)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fc19d9a-b1e3-49bd-9c20-f370da0e6bff",
      "metadata": {
        "id": "5fc19d9a-b1e3-49bd-9c20-f370da0e6bff",
        "outputId": "a5e8ab97-d900-4560-a8ff-97630a3efe75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I reach into the shadows summon Sweet Elaine\n",
            "﻿Pointing all steel values fails if friends remote empty Reply\n",
            "\n",
            "Image existing\n",
            "Long seconds confirm flesh pressed secretly Remember saint talk dying To unfamiliar pieces Father blessed\n",
            "Speech keeps passing shape raises You travel feeling shadows Thriven bodies swept Spirit consume\n"
          ]
        }
      ],
      "source": [
        "for i in range(4):\n",
        "    # create a chat completion\n",
        "    chat_completion = openai.ChatCompletion.create(model=\"gpt-3.5-turbo\",\n",
        "                                    messages=messages_list,\n",
        "                                    max_tokens = 15,\n",
        "                                    n=1,\n",
        "                                    temperature=2)\n",
        "\n",
        "    # print the chat completion\n",
        "    print(chat_completion.choices[0].message.content)\n",
        "\n",
        "    new_message = {\"role\":\"assistant\", \"content\":chat_completion.choices[0].message.content}\n",
        "    messages_list.append(new_message)\n",
        "    time.sleep(0.1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}